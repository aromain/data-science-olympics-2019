{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Winning solution of the Data Science Olympics 2019\n",
    "### Running this notebook will give you a leaderboard score of  0.44057\n",
    "### Tested on Python 2.7, but should also work on Python 3.x\n",
    "### If you have any questions, don't hesitate to contact me at \n",
    "### romain.ayres@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 31303: expected 24 fields, saw 49\n",
      "Skipping line 75954: expected 24 fields, saw 49\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load train\n",
    "train = pd.read_csv(filepath_or_buffer='data/train_requests.csv',\n",
    "                    sep=',',\n",
    "                    low_memory=False,\n",
    "                    error_bad_lines=False,\n",
    "                    index_col=0)\n",
    "# Load test\n",
    "test = pd.read_csv(filepath_or_buffer='data/test_requests.csv',\n",
    "                   sep=',',\n",
    "                   low_memory=False,\n",
    "                   error_bad_lines=False,\n",
    "                   index_col=0)\n",
    "\n",
    "# Rename target\n",
    "train.rename(columns={'granted_number_of_nights': 'target'},\n",
    "             inplace=True)\n",
    "\n",
    "# Create target in test df before train+test concatenation\n",
    "test['target'] = np.nan\n",
    "\n",
    "# Create train/test variable before train+test concatenation\n",
    "train['train'] = 1\n",
    "test['train'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenation train+test\n",
    "df = pd.concat((train[train.columns], test[train.columns]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list categorical features\n",
    "categorical_features = ['animal_presence',\n",
    "                        'child_to_come',\n",
    "                        'group_composition_label',\n",
    "                        'group_id',\n",
    "                        'group_main_requester_id',\n",
    "                        'group_type',\n",
    "                        'housing_situation_label',\n",
    "                        'long_term_housing_request',\n",
    "                        'request_backoffice_creator_id',\n",
    "                        'requester_type',\n",
    "                        'social_situation_id',\n",
    "                        'town',\n",
    "                        'victim_of_violence',\n",
    "                        'victim_of_violence_type',\n",
    "                        'district']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "for var in categorical_features:\n",
    "    encoder = LabelEncoder()\n",
    "    df['le_{}'.format(var)] = encoder.fit_transform(df[var])\n",
    "    df.loc[df[var].isnull(), 'le_{}'.format(var)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts\n",
    "for var in categorical_features:\n",
    "    mapping_vc = df[var].value_counts()\n",
    "    df['vc_{}'.format(var)] = df[var].map(mapping_vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date features\n",
    "def create_date_features(df, column):\n",
    "    df[column] = pd.to_datetime(df[column])\n",
    "    df['day_{}'.format(column)] = df[column].dt.day\n",
    "    df['week_{}'.format(column)] = df[column].dt.week\n",
    "    df['month_{}'.format(column)] = df[column].dt.month\n",
    "    df['year_{}'.format(column)] = df[column].dt.year\n",
    "    df['hour_{}'.format(column)] = df[column].dt.hour\n",
    "    df['weekday_{}'.format(column)] = df[column].dt.weekday\n",
    "    df['numeric_{}'.format(column)] = df[column].astype(np.int64) * 1e-9\n",
    "    return df\n",
    "\n",
    "for date_col in ['answer_creation_date',\n",
    "                 'group_creation_date',\n",
    "                 'request_creation_date']:\n",
    "    df[date_col] = create_date_features(df, date_col)\n",
    "    df.drop(date_col, axis=1, inplace=True)\n",
    "\n",
    "df['diff_date_1'] = (df['numeric_request_creation_date'] - \\\n",
    "                     df['numeric_group_creation_date'])\n",
    "df['diff_date_2'] = (df['numeric_answer_creation_date'] - \\\n",
    "                     df['numeric_group_creation_date'])\n",
    "df['diff_date_3'] = (df['numeric_answer_creation_date'] - \\\n",
    "                     df['numeric_request_creation_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target encoding\n",
    "def target_encoding(df, grp_col, target_col, n_folds=10):\n",
    "    df['fold'] = np.random.randint(n_folds, size=len(df))\n",
    "    df_te = pd.DataFrame()\n",
    "    for fold in df['fold'].unique():\n",
    "        df_fold = df[df['fold'] != fold].groupby(grp_col)[target_col].agg(['mean', 'count'])\n",
    "        df_fold['fold'] = fold\n",
    "        df_te = df_te.append(df_fold.reset_index())\n",
    "    df_te.rename(columns={'mean': 'te_mean_{}'.format('_'.join(grp_col)),\n",
    "                          'count': 'te_count_{}'.format('_'.join(grp_col))},\n",
    "                 inplace=True)\n",
    "    df = pd.merge(df, df_te, how='left')\n",
    "    df.drop('fold', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "te_grp_cols = [['group_id'],\n",
    "               ['group_main_requester_id'],\n",
    "               ['request_backoffice_creator_id'],\n",
    "               ['social_situation_id'],\n",
    "               ['housing_situation_id'],\n",
    "               ['district'],\n",
    "               ['town'],\n",
    "               ['social_situation_id', 'group_main_requester_id'],\n",
    "               ['social_situation_id', 'group_id'],\n",
    "               ['social_situation_id', 'request_backoffice_creator_id'],\n",
    "               ['group_main_requester_id', 'group_id'],\n",
    "               ['group_main_requester_id', 'request_backoffice_creator_id'],\n",
    "               ['group_id', 'request_backoffice_creator_id'],\n",
    "               ['social_situation_id', 'housing_situation_id'],\n",
    "               ['group_main_requester_id', 'housing_situation_id'],\n",
    "               ['group_id', 'housing_situation_id'],\n",
    "               ['request_backoffice_creator_id', 'housing_situation_id']]\n",
    "\n",
    "for grp_col in te_grp_cols:\n",
    "    df = target_encoding(df=df,\n",
    "                         grp_col=grp_col,\n",
    "                         target_col='target',\n",
    "                         n_folds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create X & X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtypes = df.dtypes.map(str)\n",
    "numerical_features = list(dtypes[dtypes.isin(['int64','float64'])].index)\n",
    "X_full = df[numerical_features].copy()\n",
    "\n",
    "X = X_full[X_full['train'] == 1].copy()\n",
    "X_test = X_full[X_full['train'] == 0].copy()\n",
    "y = X_full[X_full['train'] == 1]['target']\n",
    "\n",
    "X.drop(['target', 'train'], axis=1, inplace=True)\n",
    "X_test.drop(['target', 'train'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.3,\n",
       "        importance_type='split', learning_rate=0.03, max_depth=-1,\n",
       "        min_child_samples=10, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=400, n_jobs=-1, nthread=8, num_leaves=45,\n",
       "        objective='logloss', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb = LGBMClassifier(nthread=8,\n",
    "                     objective='logloss',\n",
    "                     n_estimators=400,\n",
    "                     num_leaves=45,\n",
    "                     learning_rate=0.03,\n",
    "                     subsample=1.0,\n",
    "                     subsample_freq=1,\n",
    "                     colsample_bytree=0.3,\n",
    "                     min_child_samples=10)\n",
    "\n",
    "lgb.fit(X, y, sample_weight=10**y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lgb.predict_proba(X_test)\n",
    "\n",
    "df_pred = pd.concat([pd.DataFrame(test.index),\n",
    "                     pd.DataFrame(preds)],\n",
    "                    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv('data/submit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
